{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries to Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from PIL import Image\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Image Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/arencarpenter/Desktop/Detecting_ALL_with_CNN/Data/training/'\n",
    "test_dir = '/Users/arencarpenter/Desktop/Detecting_ALL_with_CNN/Data/testing/'\n",
    "val_dir = '/Users/arencarpenter/Desktop/Detecting_ALL_with_CNN/Data/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create flow_from_directory objects for Keras model. Using a downsized dataset with class balance for local model running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1346 images belonging to 2 classes.\n",
      "Found 593 images belonging to 2 classes.\n",
      "Found 947 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_g = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(train_dir,\n",
    "                                                                  target_size = (256,256), \n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  class_mode='binary')\n",
    "val_g = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(val_dir,\n",
    "                                                                target_size = (256,256), \n",
    "                                                                color_mode='rgb',\n",
    "                                                                class_mode='binary')\n",
    "test_g = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(test_dir,\n",
    "                                                                target_size = (256,256), \n",
    "                                                                color_mode='rgb',\n",
    "                                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception -- 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(450, 450, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(450, 450, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1, activation ='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 140s 3s/step - loss: 0.6371 - accuracy: 0.6612 - recall: 0.6657 - val_loss: 0.5866 - val_accuracy: 0.7285 - val_recall: 0.7381\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 157s 4s/step - loss: 0.5689 - accuracy: 0.7348 - recall: 0.7504 - val_loss: 0.5515 - val_accuracy: 0.7369 - val_recall: 0.7517\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 149s 3s/step - loss: 0.5432 - accuracy: 0.7422 - recall: 0.7221 - val_loss: 0.5315 - val_accuracy: 0.7521 - val_recall: 0.7789\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 147s 3s/step - loss: 0.5259 - accuracy: 0.7600 - recall: 0.7340 - val_loss: 0.5498 - val_accuracy: 0.7167 - val_recall: 0.8946\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 145s 3s/step - loss: 0.5078 - accuracy: 0.7615 - recall: 0.7563 - val_loss: 0.5155 - val_accuracy: 0.7589 - val_recall: 0.7891\n",
      "Total Time Elapsed:  12  minutes  34  seconds\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', 'Recall'])\n",
    "start = timer()\n",
    "model.fit(train_g, \n",
    "            epochs=5, \n",
    "            validation_data=val_g, \n",
    "            workers = 7)\n",
    "end = timer()\n",
    "elapsed = end - start\n",
    "print('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 65s 2s/step - loss: 0.9548 - accuracy: 0.4340 - recall: 0.2685\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_g, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception -- 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(450, 450, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(450, 450, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1, activation ='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "43/43 [==============================] - 142s 3s/step - loss: 0.6473 - accuracy: 0.6367 - recall: 0.6865 - val_loss: 0.6001 - val_accuracy: 0.7403 - val_recall: 0.5782\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 152s 4s/step - loss: 0.5757 - accuracy: 0.7318 - recall: 0.6909 - val_loss: 0.5587 - val_accuracy: 0.7302 - val_recall: 0.7959\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 150s 3s/step - loss: 0.5401 - accuracy: 0.7511 - recall: 0.7251 - val_loss: 0.5347 - val_accuracy: 0.7504 - val_recall: 0.7823\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 148s 3s/step - loss: 0.5240 - accuracy: 0.7541 - recall: 0.7400 - val_loss: 0.5265 - val_accuracy: 0.7521 - val_recall: 0.7891\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 148s 3s/step - loss: 0.5080 - accuracy: 0.7689 - recall: 0.7578 - val_loss: 0.5233 - val_accuracy: 0.7504 - val_recall: 0.8163\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 147s 3s/step - loss: 0.5003 - accuracy: 0.7704 - recall: 0.7593 - val_loss: 0.5128 - val_accuracy: 0.7622 - val_recall: 0.7891\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 147s 3s/step - loss: 0.4926 - accuracy: 0.7741 - recall: 0.7637 - val_loss: 0.5315 - val_accuracy: 0.7555 - val_recall: 0.8878\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 147s 3s/step - loss: 0.4891 - accuracy: 0.7704 - recall: 0.7786 - val_loss: 0.5226 - val_accuracy: 0.7555 - val_recall: 0.8537\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 148s 3s/step - loss: 0.4814 - accuracy: 0.7749 - recall: 0.7682 - val_loss: 0.5084 - val_accuracy: 0.7656 - val_recall: 0.8197\n",
      "Epoch 10/15\n",
      "43/43 [==============================] - 146s 3s/step - loss: 0.4740 - accuracy: 0.7875 - recall: 0.7697 - val_loss: 0.5090 - val_accuracy: 0.7622 - val_recall: 0.8197\n",
      "Epoch 11/15\n",
      "43/43 [==============================] - 146s 3s/step - loss: 0.4684 - accuracy: 0.7845 - recall: 0.7890 - val_loss: 0.5075 - val_accuracy: 0.7774 - val_recall: 0.7347\n",
      "Epoch 12/15\n",
      "43/43 [==============================] - 145s 3s/step - loss: 0.4645 - accuracy: 0.7905 - recall: 0.7682 - val_loss: 0.5084 - val_accuracy: 0.7639 - val_recall: 0.8265\n",
      "Epoch 13/15\n",
      "43/43 [==============================] - 144s 3s/step - loss: 0.4617 - accuracy: 0.7883 - recall: 0.7771 - val_loss: 0.5145 - val_accuracy: 0.7605 - val_recall: 0.8401\n",
      "Epoch 14/15\n",
      "43/43 [==============================] - 143s 3s/step - loss: 0.4579 - accuracy: 0.7853 - recall: 0.7875 - val_loss: 0.4932 - val_accuracy: 0.7926 - val_recall: 0.8129\n",
      "Epoch 15/15\n",
      "43/43 [==============================] - 143s 3s/step - loss: 0.4537 - accuracy: 0.7942 - recall: 0.7890 - val_loss: 0.4922 - val_accuracy: 0.7892 - val_recall: 0.7891\n",
      "Total Time Elapsed:  37  minutes  18  seconds\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', 'Recall'])\n",
    "start = timer()\n",
    "model.fit(train_g, \n",
    "            epochs=15, \n",
    "            validation_data=val_g, \n",
    "            workers = 7)\n",
    "end = timer()\n",
    "elapsed = end - start\n",
    "print('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 68s 2s/step - loss: 1.0511 - accuracy: 0.4636 - recall: 0.2778\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_g, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
